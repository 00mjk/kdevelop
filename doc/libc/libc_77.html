<HTML>
<HEAD>
<!-- This HTML file has been created by texi2html 1.51
     from libc.texinfo on 28 March 2001 -->

<TITLE>The GNU C Library - Extended Char Intro</TITLE>
</HEAD>
<BODY>
Go to the <A HREF="libc_1.html">first</A>, <A HREF="libc_76.html">previous</A>, <A HREF="libc_78.html">next</A>, <A HREF="libc_654.html">last</A> section, <A HREF="libc_toc.html">table of contents</A>.
<P><HR><P>


<H2><A NAME="SEC77" HREF="libc_toc.html#TOC77">Introduction to Extended Characters</A></H2>

<P>
A variety of solutions to overcome the differences between
character sets with a 1:1 relation between bytes and characters and
character sets with ratios of 2:1 or 4:1 exist. The remainder of this
section gives a few examples to help understand the design decisions
made while developing the functionality of the C library.

</P>
<P>
<A NAME="IDX503"></A>
A distinction we have to make right away is between internal and
external representation.  <STRONG>Internal representation</STRONG> means the
representation used by a program while keeping the text in memory.
External representations are used when text is stored or transmitted
through whatever communication channel.  Examples of external
representations include files lying in a directory that are going to be
read and parsed.

</P>
<P>
Traditionally there was no difference between the two representations.
It was equally comfortable and useful to use the same one-byte
representation internally and externally.  This changes with more and
larger character sets.

</P>
<P>
One of the problems to overcome with the internal representation is
handling text which is externally encoded using different character
sets.  Assume a program which reads two texts and compares them using
some metric.  The comparison can be usefully done only if the texts are
internally kept in a common format.

</P>
<P>
<A NAME="IDX504"></A>
For such a common format (@math{=} character set) eight bits are certainly
no longer enough.  So the smallest entity will have to grow: <STRONG>wide
characters</STRONG> will now be used.  Instead of one byte, two or four will
be used instead.  (Three are not good to address in memory and more
than four bytes seem not to be necessary).

</P>
<P>
<A NAME="IDX505"></A>
<A NAME="IDX506"></A>
As shown in some other part of this manual,
there exists a completely new family of functions which can handle texts
of this kind in memory.  The most commonly used character set for such
internal wide character representations are Unicode and ISO 10646.
The former is a subset of the latter and used when wide characters are
chosen to by 2 bytes (@math{= 16} bits) wide.  The standard names of the
<A NAME="IDX507"></A>
<A NAME="IDX508"></A>
encodings used in these cases are UCS2 (@math{= 16} bits) and UCS4
(@math{= 32} bits).

</P>
<P>
To represent wide characters the <CODE>char</CODE> type is not suitable.  For
this reason the ISO C standard introduces a new type which is
designed to keep one character of a wide character string.  To maintain
the similarity there is also a type corresponding to <CODE>int</CODE> for
those functions which take a single wide character.

</P>
<P>
<DL>
<DT><U>Data type:</U> <B>wchar_t</B>
<DD><A NAME="IDX509"></A>
This data type is used as the base type for wide character strings.
I.e., arrays of objects of this type are the equivalent of <CODE>char[]</CODE>
for multibyte character strings.  The type is defined in <TT>`stddef.h'</TT>.

</P>
<P>
The ISO C89 standard, where this type was introduced, does not say
anything specific about the representation.  It only requires that this
type is capable to store all elements of the basic character set.
Therefore it would be legitimate to define <CODE>wchar_t</CODE> and
<CODE>char</CODE>.  This might make sense for embedded systems.

</P>
<P>
But for GNU systems this type is always 32 bits wide.  It is therefore
capable to represent all UCS4 value therefore covering all of ISO
10646.  Some Unix systems define <CODE>wchar_t</CODE> as a 16 bit type and
thereby follow Unicode very strictly.  This is perfectly fine with the
standard but it also means that to represent all characters from Unicode
and ISO 10646 one has to use surrogate character which is in fact a
multi-wide-character encoding.  But this contradicts the purpose of the
<CODE>wchar_t</CODE> type.
</DL>

</P>
<P>
<DL>
<DT><U>Data type:</U> <B>wint_t</B>
<DD><A NAME="IDX510"></A>
<CODE>wint_t</CODE> is a data type used for parameters and variables which
contain a single wide character.  As the name already suggests it is the
equivalent to <CODE>int</CODE> when using the normal <CODE>char</CODE> strings.  The
types <CODE>wchar_t</CODE> and <CODE>wint_t</CODE> have often the same
representation if their size if 32 bits wide but if <CODE>wchar_t</CODE> is
defined as <CODE>char</CODE> the type <CODE>wint_t</CODE> must be defined as
<CODE>int</CODE> due to the parameter promotion.

</P>
<P>
<A NAME="IDX511"></A>
This type is defined in <TT>`wchar.h'</TT> and got introduced in the second
amendment to ISO C 89.
</DL>

</P>
<P>
As there are for the <CODE>char</CODE> data type there also exist macros
specifying the minimum and maximum value representable in an object of
type <CODE>wchar_t</CODE>.

</P>
<P>
<DL>
<DT><U>Macro:</U> wint_t <B>WCHAR_MIN</B>
<DD><A NAME="IDX512"></A>
The macro <CODE>WCHAR_MIN</CODE> evaluates to the minimum value representable
by an object of type <CODE>wint_t</CODE>.

</P>
<P>
This macro got introduced in the second amendment to ISO C89.
</DL>

</P>
<P>
<DL>
<DT><U>Macro:</U> wint_t <B>WCHAR_MAX</B>
<DD><A NAME="IDX513"></A>
The macro <CODE>WCHAR_MIN</CODE> evaluates to the maximum value representable
by an object of type <CODE>wint_t</CODE>.

</P>
<P>
This macro got introduced in the second amendment to ISO C89.
</DL>

</P>
<P>
Another special wide character value is the equivalent to <CODE>EOF</CODE>.

</P>
<P>
<DL>
<DT><U>Macro:</U> wint_t <B>WEOF</B>
<DD><A NAME="IDX514"></A>
The macro <CODE>WEOF</CODE> evaluates to a constant expression of type
<CODE>wint_t</CODE> whose value is different from any member of the extended
character set.

</P>
<P>
<CODE>WEOF</CODE> need not be the same value as <CODE>EOF</CODE> and unlike
<CODE>EOF</CODE> it also need <EM>not</EM> be negative.  I.e., sloppy code like

</P>

<PRE>
{
  int c;
  ...
  while ((c = getc (fp)) &#60; 0)
    ...
}
</PRE>

<P>
has to be rewritten to explicitly use <CODE>WEOF</CODE> when wide characters
are used.

</P>

<PRE>
{
  wint_t c;
  ...
  while ((c = wgetc (fp)) != WEOF)
    ...
}
</PRE>

<P>
<A NAME="IDX515"></A>
This macro was introduced in the second amendment to ISO C89 and is
defined in <TT>`wchar.h'</TT>.
</DL>

</P>

<P>
These internal representations present problems when it comes to storing
and transmittal, since a single wide character consists of more
than one byte they are effected by byte-ordering.  I.e., machines with
different endianesses would see different value accessing the same data.
This also applies for communication protocols which are all byte-based
and therefore the sender has to decide about splitting the wide
character in bytes.  A last (but not least important) point is that wide
characters often require more storage space than an customized byte
oriented character set.

</P>
<P>
<A NAME="IDX516"></A>
<A NAME="IDX517"></A>
   For all the above reasons, an external encoding which is different
from the internal encoding is often used if the latter is UCS2 or UCS4.
The external encoding is byte-based and can be chosen appropriately for
the environment and for the texts to be handled.  There exist a variety
of different character sets which can be used for this external
encoding. Information which will not be exhaustively presented
here--instead, a description of the major groups will suffice.  All of
the ASCII-based character sets [_bkoz_: do you mean Roman character
sets? If not, what do you mean here?]  fulfill one requirement: they are
"filesystem safe".  This means that the character <CODE>'/'</CODE> is used in
the encoding <EM>only</EM> to represent itself.  Things are a bit
different for character sets like EBCDIC (Extended Binary Coded Decimal
Interchange Code, a character set family used by IBM) but if the
operation system does not understand EBCDIC directly the parameters to
system calls have to be converted first anyhow.

</P>

<UL>
<LI>

The simplest character sets are one-byte character sets.  There can be
only up to 256 characters (for 8 bit character sets) which is not
sufficient to cover all languages but might be sufficient to handle a
specific text.  Another reason to choose this is because of constraints
from interaction with other programs (which might not be 8-bit clean).

<A NAME="IDX518"></A>
<LI>

The ISO 2022 standard defines a mechanism for extended character
sets where one character <EM>can</EM> be represented by more than one
byte.  This is achieved by associating a state with the text.  Embedded
in the text can be characters which can be used to change the state.
Each byte in the text might have a different interpretation in each
state.  The state might even influence whether a given byte stands for a
character on its own or whether it has to be combined with some more
bytes.

<A NAME="IDX519"></A>
<A NAME="IDX520"></A>
In most uses of ISO 2022 the defined character sets do not allow
state changes which cover more than the next character.  This has the
big advantage that whenever one can identify the beginning of the byte
sequence of a character one can interpret a text correctly.  Examples of
character sets using this policy are the various EUC character sets
(used by Sun's operations systems, EUC-JP, EUC-KR, EUC-TW, and EUC-CN)
or SJIS (Shift JIS, a Japanese encoding).

But there are also character sets using a state which is valid for more
than one character and has to be changed by another byte sequence.
Examples for this are ISO-2022-JP, ISO-2022-KR, and ISO-2022-CN.

<LI>

<A NAME="IDX521"></A>
Early attempts to fix 8 bit character sets for other languages using the
Roman alphabet lead to character sets like ISO 6937.  Here bytes
representing characters like the acute accent do not produce output
themselves: one has to combine them with other characters to get the
desired result.  E.g., the byte sequence <CODE>0xc2 0x61</CODE> (non-spacing
acute accent, following by lower-case `a') to get the "small a with
acute" character.  To get the acute accent character on its on one has
to write <CODE>0xc2 0x20</CODE> (the non-spacing acute followed by a space).

This type of characters sets is quite frequently used in embedded
systems such as video text.

<LI>

<A NAME="IDX522"></A>
Instead of converting the Unicode or ISO 10646 text used internally
it is often also sufficient to simply use an encoding different than
UCS2/UCS4.  The Unicode and ISO 10646 standards even specify such an
encoding: UTF-8.  This encoding is able to represent all of ISO
10464 31 bits in a byte string of length one to seven.

<A NAME="IDX523"></A>
There were a few other attempts to encode ISO 10646 such as UTF-7
but UTF-8 is today the only encoding which should be used.  In fact,
UTF-8 will hopefully soon be the only external which has to be
supported.  It proves to be universally usable and the only disadvantage
is that it favor Roman languages very much by making the byte string
representation of other scripts (Cyrillic, Greek, Asian scripts) longer
than necessary if using a specific character set for these scripts.
Methods like the Unicode compression scheme can alleviate these
problems.
</UL>

<P>
The question remaining is: how to select the character set or encoding
to use.  The answer: you cannot decide about it yourself, it is decided
by the developers of the system or the majority of the users.  Since the
goal is interoperability one has to use whatever the other people one
works with use.  If there are no constraints the selection is based on
the requirements the expected circle of users will have.  I.e., if a
project is expected to only be used in, say, Russia it is fine to use
KOI8-R or a similar character set.  But if at the same time people from,
say, Greece are participating one should use a character set which allows
all people to collaborate.

</P>
<P>
The most widely useful solution seems to be: go with the most general
character set, namely ISO 10646.  Use UTF-8 as the external encoding
and problems about users not being able to use their own language
adequately are a thing of the past.

</P>
<P>
One final comment about the choice of the wide character representation
is necessary at this point.  We have said above that the natural choice
is using Unicode or ISO 10646.  This is not specified in any
standard, though.  The ISO C standard does not specify anything
specific about the <CODE>wchar_t</CODE> type.  There might be systems where
the developers decided differently.  Therefore one should as much as
possible avoid making assumption about the wide character representation
although GNU systems will always work as described above.  If the
programmer uses only the functions provided by the C library to handle
wide character strings there should not be any compatibility problems
with other systems.

</P>
<P><HR><P>
Go to the <A HREF="libc_1.html">first</A>, <A HREF="libc_76.html">previous</A>, <A HREF="libc_78.html">next</A>, <A HREF="libc_654.html">last</A> section, <A HREF="libc_toc.html">table of contents</A>.
</BODY>
</HTML>
